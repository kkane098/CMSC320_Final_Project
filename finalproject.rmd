---
title: "CMSC320 Final Project"
author: "Kevin Kane, Matthew Sinnott"
date: "May 7, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include = FALSE}
read_csv <- "[read_csv()](https://readr.tidyverse.org/reference/read_delim.html)"

select <- "[select()](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/select)"
mutate <- "[mutate()](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/mutate)"
filter <- "[filter()](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/filter)"
factor <- "[factor()](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/factor)"
levels <- "[levels()](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/levels)"
table <- "[table()](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/table)"
lm <- "[lm()](https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/lm)"
glance <- "[glance()](https://www.rdocumentation.org/packages/broom/versions/0.4.4/topics/glance)"
tidy <- "[tidy()](https://www.rdocumentation.org/packages/broom/versions/0.4.4/topics/tidy)"
augment <- "[augment()](https://www.rdocumentation.org/packages/broom/versions/0.4.4/topics/augment)"

str_detect <- "[str_detect()](https://www.rdocumentation.org/packages/stringr/versions/1.4.0/topics/str_detect)"
str_replace <- "[str_replace()](https://www.rdocumentation.org/packages/stringr/versions/1.4.0/topics/str_replace)"
as.double <- "[as.double()](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/double)"
```

## Introduction:
This tutorial will walk you through many of the major aspects of data science, including data cleaning, exploratory data analysis, hypothesis testing, machine learning, and curation of a message.

To begin, let's examine the dataset we will be using throughout this tutorial.  This dataset contains data from thousands of AirBnb listings in San Fransisco.  To download the data we are using, visit [here](http://insideairbnb.com/get-the-data.html) and click on the listing.csv.gz link.  The csv can be loaded into R as follows.

```{r load_csv, warning=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
dat <- read_csv("listings_sf_all.csv")
head(dat)
```

Note that this code will only work if it is run in the same directory as the csv, otherwise you need to pass `r read_csv` the full filepath to where the csv is stored.

## Part 1 - Cleaning:
Often, as is the case here, when you load your data you will need to do some extra processing to make it easier to use in later analysis. This step is commonly referred to as **cleaning**.  

For example, this dataset has all the information you would expect to find in an AirBnb listing, but much of that information, such as URL data and text descriptions, is not especially useful for analysis. So, a good first step is to eliminate unnecessary columns to make the data a little easier to read and work with. A good tool to do this is the `r select` function, which can be passed a list of columns from a data frame and will return a new data frame with only those columns.  The following `r select` call should leave us with only the useful data.

```{r select_dat}
selected_dat <- dat %>% 
  select(host_id, host_since, host_response_time, host_response_rate, 
         host_is_superhost, host_listings_count, host_identity_verified, 
         neighbourhood_cleansed, zipcode, latitude, longitude, 
         id, property_type, room_type, accommodates, bathrooms, bedrooms, beds, bed_type, amenities, square_feet, 
         price, weekly_price, monthly_price, security_deposit, cleaning_fee, guests_included, extra_people, 
         minimum_nights, maximum_nights, availability_30, availability_60, availability_90, availability_365, 
         number_of_reviews, number_of_reviews_ltm, review_scores_rating, reviews_per_month)

selected_dat %>% head()
```

As you can see, this new data frame is much cleaner and will be easier to work with going forward.

However, we are far from done with cleaning. A closer inspection of some of the columns reveals a new issue.

```{r explanation_1}
selected_dat %>% 
  select(amenities, price, weekly_price, monthly_price) %>%
  head()
```

Many of the columns in our dataset are in forms that make them tricky to deal with.  For example, all the prices are still stored as strings, when we would really like them to be stored as doubles.  Additionally, the amenities column has a lot of useful information about the listing, but that information is difficult to use as is.

Let's start by extracting the useful data from the amenities column.  A key function we'll use here is the `r mutate` function, which stores the result of an operation preformed on a column in a new column.  Combining `r mutate` with the `r str_detect` function allows us to create several new logical columns that represent the data contained in the amenities column in a way that will make it much easier to use later. Having transferred all the useful data from the amenities column, we can also now safely remove it.

```{r fix_amenities}
fixed_amenities <- selected_dat %>% 
  mutate(has_internet = str_detect(amenities, "Wifi") || str_detect(amenities, "Internet")) %>%
  mutate(has_tv = str_detect(amenities, "TV")) %>%
  mutate(has_kitchen = str_detect(amenities, "Kitchen")) %>%
  mutate(has_washer = str_detect(amenities, "Washer")) %>%
  mutate(has_dryer = str_detect(amenities, "Dryer")) %>%
  mutate(has_heating = str_detect(amenities, "Heating")) %>%
  mutate(has_ac = str_detect(amenities, "Air conditioning")) %>% 
  mutate(pets_allowed = str_detect(amenities, "Pets allowed")) %>%
  select(-amenities)

fixed_amenities %>% 
  select(has_internet, has_tv, has_kitchen, has_washer, has_dryer, has_heating, has_ac, pets_allowed) %>%
  head()
```

Now let's take a look at the price columns.  Currently, prices are stored as strings and cannot be converted to doubles because of the presence of '$' and ',' characters.  However, these can be removed by calling `r str_replace` with the empty string.  After that, we can safely convert the price columns to doubles using `r as.double`.

```{r fix_prices}
fixed_prices <- fixed_amenities %>% 
  mutate(price            = as.double(str_replace(str_replace(price,            ',', ''), '\\$', ''))) %>%
  mutate(weekly_price     = as.double(str_replace(str_replace(weekly_price,     ',', ''), '\\$', ''))) %>%
  mutate(monthly_price    = as.double(str_replace(str_replace(monthly_price,    ',', ''), '\\$', ''))) %>%
  mutate(security_deposit = as.double(str_replace(str_replace(security_deposit, ',', ''), '\\$', ''))) %>%
  mutate(cleaning_fee     = as.double(str_replace(str_replace(cleaning_fee,     ',', ''), '\\$', ''))) %>%
  mutate(extra_people     = as.double(str_replace(str_replace(extra_people,     ',', ''), '\\$', '')))
```

However, there is still a problem with the prices. 

```{r explanation_2}
fixed_prices %>% 
  select(price, weekly_price, monthly_price, security_deposit, cleaning_fee, extra_people) %>% 
  head()
```

As you can see, several prices are encoded as 'NA' in the table.  This is referred to as **missing data** and there are several ways to deal with it.  General options are to replace the missing data with the mean value of the column or the predicted value from some model.  However, in this case we can use our knowledge of the data to replace the missing values.  The weekly_price and monthly_price columns represent special rates provided by the owner of the listing for visitors with longer stays.  If they are 'NA', that means that there is no discount and those missing values can be replaced by the nightly price (the price column) multiplied by 7 or 30 respectively.  We can also safely assume that if the security_deposit or cleaning_fee columns are 'NA' that there is no required security deposit or cleaning fee, so those missing values can be replaced with 0.

```{r fix_prices_2}
fixed_prices <- fixed_prices %>%
  mutate(weekly_price     = ifelse(is.na(weekly_price),     price*7, weekly_price)) %>%
  mutate(monthly_price    = ifelse(is.na(monthly_price),    price*30, monthly_price)) %>%
  mutate(security_deposit = ifelse(is.na(security_deposit), 0, security_deposit)) %>%
  mutate(cleaning_fee     = ifelse(is.na(cleaning_fee),     0, cleaning_fee))

fixed_prices %>% 
  select(price, weekly_price, monthly_price, security_deposit, cleaning_fee, extra_people) %>%
  head()
```

Another thing that will be helpful later is encoding the columns that represent categorical variables (variables that can take on a value from a small set of values) as factors. Specifically, we want to ensure that our model will treat variables like zipcode and bedrooms as categorical variables rather than continuous numbers. We can do this using the `r factor` function.

```{r make_factors}
factor_dat <- fixed_prices %>% 
  mutate(property_type = factor(property_type)) %>%
  mutate(room_type = factor(room_type)) %>%
  mutate(zipcode = factor(zipcode)) %>%
  mutate(neighbourhood = factor(neighbourhood_cleansed)) %>%
  mutate(host_response_time = factor(host_response_time)) %>%
  mutate(bed_type = factor(bed_type)) %>%
  mutate(bedrooms = factor(bedrooms)) %>%
  mutate(bathrooms = factor(bathrooms)) %>%
  mutate(beds = factor(beds)) %>%
  mutate(accommodates = factor(accommodates)) %>%
  select(-neighbourhood_cleansed)

factor_dat %>% 
  select(property_type, room_type, zipcode, neighbourhood, host_response_time, bed_type, bedrooms, bathrooms, beds, accommodates) %>%
  head()
```

Storing these columns as factors also allows us to easily check the range of values stored in each column using the `r levels` function. We can also easily view the number of rows associated with each value using the `r table` function.

```{r explanation_3}
levels(factor_dat$property_type)

table(factor_dat$bedrooms)
```

For more information on factors in R and why they are useful check [here](https://www.stat.berkeley.edu/~s133/factors.html).


```{r fix_hosts}
host_fixed_dat <- factor_dat %>%
  mutate(host_response_rate = ifelse(is.na(host_response_rate), '0%', host_response_rate)) %>%
  mutate(host_response_rate = ifelse(host_response_rate == 'N/A', '0%', host_response_rate)) %>%
  mutate(host_response_rate = 0.01 * as.double(str_replace(host_response_rate, '%', '')))

host_fixed_dat %>% select(host_response_rate) %>% head()
```


## EDA

First, we do some simple graphs to get a better feel for the dataset. The first graph we plot is of the distribution of prices. As you can see from the violin plot, the data is heavily skewed - the vast majority of prices are quite low, but there is a long tail of increasing prices going all the way up to $10,000.

```{r log_dat, message= FALSE, warning= FALSE}
host_fixed_dat %>% 
  ggplot(aes(x="", y = price)) + 
  geom_violin() + 
  labs(title = "Distribution of Price", y = "Price", x = "")
```

Skew is calculated by how far the median is from the average of the first and third quantile of the data. When calculating the skew for the price, we get a skew of \$35, which is quite significant given that the average price for an accomodation is \$213.
```{r} 
host_fixed_dat %>% 
  summarize(mean_price = mean(price))
```

Additionally, we can see that the median is also very different from the mean - they differ by almost $65 dollars. This high degree of skew makes the data difficult to work with and graph.
```{r}
skew_dat <- host_fixed_dat %>% 
  summarise(median = median(price), first_q = quantile(price, 1/4), third_q = quantile(price, 3/4)) %>%
  mutate(skew = (median - first_q) - (third_q - median))

skew_dat
```

In order to learn more about the skew, we took a closer look at the properties with cost greater than \$5000. There are only 5 of them in a dataset of more than 7,000, making them sigificant outliers. In order to get a better sense of what these data points were, we joined in the listing url to allow us to look at the whole listing. Because there are only 5 listings, we went through them individually so that we could find out what was happening. All 5 of these price values are incorrect - the first, second and fourth are 550, 60 and 1100 respectively, while the third and fifth listings are no longer availible. Given that these listings are all in error, we can safely remove them from the dataset.

```{r}
host_fixed_dat %>% 
  filter(price >= 5000) %>%
  select(id, price, number_of_reviews) %>%
  inner_join(dat %>% select(id, listing_url), by=c("id"))

clean_dat <- host_fixed_dat %>% filter(price < 5000)
```


```{r}
log_price_dat <- host_fixed_dat%>% filter(price > 0) %>% mutate(log_price = log10(price))

log_skew_dat <- log_price_dat %>% summarise(median = median(log_price), 
                                             first_q = quantile(log_price, 1/4), 
                                             third_q = quantile(log_price, 3/4)) %>% 
  mutate(skew = (median - first_q) - (third_q - median))

log_skew_dat

log_price_dat %>% 
  ggplot(aes(x="", y = log_price)) + 
  geom_boxplot() + 
  labs(title = "Distribution of Transformed Price", y = "Price (logbase10)", x = "")
```

```{r boxplots, message= FALSE, warning= FALSE}
log_price_dat %>% 
  ggplot(aes(x = neighbourhood, y = log_price, group = neighbourhood)) + 
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = "Distribution of Price by Neighbourhood", y = "Price (logbase10)", x = "Neighbourhood")

log_price_dat %>% 
  ggplot(aes(x = property_type, y = log_price, group = property_type)) + 
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = "Distribution of Price by Property Type", y = "Price (logbase10)", x = "Property Type")

log_price_dat %>% 
  ggplot(aes(x = room_type, y = log_price, group = room_type)) + 
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = "Distribution of Price by Room Type", y = "Price (logbase10)", x = "Room Type")

log_price_dat %>% 
  ggplot(aes(x = bedrooms, y = log_price, group = bedrooms)) + 
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = "Distribution of Price by Number of Bedrooms", y = "Price (logbase10)", x = "Bedrooms")

log_price_dat %>% ggplot(aes(x = has_ac, y = log_price)) + 
  geom_boxplot() +
  labs(title = "Distribution of Price Based on Whether Listing has Air Conditioning", y = "Price (logbase10)", x = "Has AC?")

```

##Linear Modeling
So, the work we did in EDA allowed us to examine general trends in how variables like number of bedrooms affect the price.  However, we cannot really make any conclusive statements about the quality of any these variables as predictors of price with the information we have so far.  This is where linear modeling comes in.  A **linear model** essentially refers an equation of the form $Y = B_0 + B_1X_1+ B_2X_2 ...$ representing a linear combination of independent variables used to predict the value of a single dependent variable (in this case price).  Using the `r lm` function, we can train a linear model to learn the appropriate values of the coefficients in the linear combination (the $B_i$s in the equation above).  We can then use functions from the broom library such as `r tidy`, `r glance`, and `r augment` to view information about the created model.  A more detailed explanation of linear models can be found [here](http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm).

```{r model1}
library(broom)
model1 <- lm(log_price~bedrooms+bathrooms, data = log_price_dat)
model1_stats <- model1 %>% glance()

model1_stats
```

In the code above, we model the log of the price of a listing using only the number of bedrooms and bathrooms.  However, a look at the output of the `r glance` function tells us this model is not very good.  The $R^2$ value is a measure of how well the model fits the data.  In a good model, we want this value to be as close to 1 as possible.  However, the fact that this model's $R^2$ value is so low is not that surprising, there are obviously many more factors that affect the price of a listing than just the number of bedrooms and bathrooms.  So let's try a model that incorporates more variables.

```{r model2}
model2 <- lm(log_price~bedrooms+bathrooms+beds+accommodates+room_type+property_type+neighbourhood+has_ac+has_tv+has_washer+has_dryer+has_internet+has_kitchen+has_heating+pets_allowed+review_scores_rating, data = log_price_dat)
model2_stats <-model2 %>% glance()

model2_stats
```

As expected, this model, which uses almost all of the useful columns from the dataset, is much better.  But do we really need all of these variables?  In general, in order to make your model as clear as possible you only want to include the variables that have a clear effect on the output variable.  This is where an element of **hypothesis testing** comes into play.  In this case, the hypothesis we want to test is whether a specific variable has any impact on the price.  However, this is difficult to prove directly, so we instead make use of a **null hypothesis**, which in this case is that a specific variable has no effect on the price.  If the probability of the null hypothesis being true is low (conventionally <.05), then we can reject it, meaning we can say with high probability the variable has an effect on the price.  Conveniently, the `r tidy` function includes the probabilities associated with the null hypothesis for each variable.

```{r}
model2_coeffs <- model2 %>% tidy()

model2_coeffs %>% head()
```

So let's examine the variables for which we cannot reject the null hypothesis.

```{r}
model2_coeffs %>% filter(p.value > .05) %>% kable()
```

We clearly cannot say anything meaningful about the effect the presence of a washer, dryer, or kitchen has on price.  However, analysis of the other variables is a little trickier, as the other variables all represent portions of a single categorical variable.  So how do we handle categorical variables for which we can only reject the null hypothesis for some of the domain? Here, it is best to do so on a case by case basis.  For property_type, neighborhood, and accomodates, the values for which we cannot reject the null hypothesis represent a relatively small portion of the domain, so discarding these variables entirely would likely be unwise.  For beds and bathrooms, it is best to examine the distribution of listings across the domain.

```{r}
table(log_price_dat$bathrooms)
table(log_price_dat$beds)
```

As you can see, the values of bathrooms for which we cannot reject the null hypothesis represent a very small number of listings.  In contrast, the values of beds for which we cannot reject the null hypothesis represent a large portion of listings.  As such, we should still include bathrooms in our model, whereas beds can likely be disregarded.

So let's examine a linear model without beds, has_kitchen, has_washer, and has_dryer.

```{r model 3}
model3 <- lm(log_price~bedrooms+bathrooms+accommodates+room_type+property_type+neighbourhood+has_ac+has_tv+pets_allowed+review_scores_rating, data = log_price_dat)
model3_coeffs <- model3 %>% tidy()
model3_stats <- model3 %>% glance()
model3_aug <- model3 %>% augment()

model3_stats
```

Even though we discarded four variables, the new model's $R^2$ value is only .001 lower! This means this smaller model will be much better to use going forward.

However, before we can move on and analyze the coefficients in this new model, there is one last thing we should do.  In order to verify our assumption of a linear relationship between the variables and price, we need to ensure that there are no trends in the residuals (the difference between the predicted value and the observed value).  If our model is sound, the residuals should be uniformly and randomly clustered around 0 when plotted against the fitted value (the log price).

```{r}
model3_aug %>% ggplot(aes(x=.fitted,y=.resid)) + geom_point() + geom_smooth(method = "loess") + labs(x="Fitted", y="Residual")
```

As the above graph meets the listed requirements, our model is sound and can now be analyzed appropriately.